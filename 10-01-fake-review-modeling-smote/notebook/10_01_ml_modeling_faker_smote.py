# -*- coding: utf-8 -*-
"""10_1_ml_modeling_FakeR_SMOTE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yNmHs0KMbbHWjuIhplY0iqWcMpmvunj-
"""

# Core packages
import pandas as pd
import numpy as np
import joblib

# Modeling & evaluation
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay

# SMOTE
from imblearn.over_sampling import SMOTE

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_parquet("/content/engineered_features.parquet")
structured_features = joblib.load("/content/feature_names.json")

X = df[structured_features]
y = df['fake_review_label']

print("Original class distribution:\n", y.value_counts())

smote = SMOTE(random_state=42)
X_smote, y_smote = smote.fit_resample(X, y)

print("After SMOTE:\n", pd.Series(y_smote).value_counts())

X_train, X_temp, y_train, y_temp = train_test_split(
    X_smote, y_smote, train_size=0.6, stratify=y_smote, random_state=42
)
X_test, X_val, y_test, y_val = train_test_split(
    X_temp, y_temp, train_size=0.5, stratify=y_temp, random_state=42
)

print("Train:", X_train.shape, "Test:", X_test.shape, "Validation:", X_val.shape)

def train_and_evaluate(model, name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    print(f"\n Evaluation: {name}")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))
    print(f"AUC-ROC: {roc_auc_score(y_test, y_proba):.4f}")

    RocCurveDisplay.from_predictions(y_test, y_proba)
    plt.title(f"ROC Curve â€” {name}")
    plt.show()

    return model

lr_smote = train_and_evaluate(LogisticRegression(max_iter=1000), "Logistic Regression (SMOTE)")

rf_smote = train_and_evaluate(RandomForestClassifier(n_estimators=100), "Random Forest (SMOTE)")

xgb_smote = train_and_evaluate(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), "XGBoost (SMOTE)")

def evaluate_on_validation(model, name):
    y_val_pred = model.predict(X_val)
    y_val_proba = model.predict_proba(X_val)[:, 1]

    print(f"\n Validation: {name}")
    print(classification_report(y_val, y_val_pred))
    print("Confusion Matrix:")
    print(confusion_matrix(y_val, y_val_pred))
    print(f"AUC-ROC: {roc_auc_score(y_val, y_val_proba):.4f}")

evaluate_on_validation(xgb_smote, "XGBoost (SMOTE)")

joblib.dump(xgb_smote, "/content/ml_model_smote.pkl")
print("Saved model as ml_model_smote.pkl")

models = {
    "LogReg (SMOTE)": lr_smote,
    "RF (SMOTE)": rf_smote,
    "XGB (SMOTE)": xgb_smote
}

results = []
for name, model in models.items():
    y_pred = model.predict(X_val)
    y_proba = model.predict_proba(X_val)[:, 1]
    auc = roc_auc_score(y_val, y_proba)
    f1 = classification_report(y_val, y_pred, output_dict=True)['weighted avg']['f1-score']
    results.append((name, round(auc, 4), round(f1, 4)))

comparison_df = pd.DataFrame(results, columns=["Model", "AUC-ROC", "F1 Score"])
comparison_df.sort_values(by="AUC-ROC", ascending=False)