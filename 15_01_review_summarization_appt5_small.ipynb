{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwattsnogueira/rating-predictor-spam-detection-review-summarizer/blob/main/15_01_review_summarization_appt5_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers gradio pandas scikit-learn --quiet"
      ],
      "metadata": {
        "id": "8tjJF044AFQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq1md2Gx-vV_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bc960e7f54c345c7a850459302e26255",
            "1f1ae3ac4be94386afec97f37d7c2f43",
            "5413fcc17c59400cb47afefd50f777c9",
            "4281ef1a1c764c53b1281b8759575f24",
            "d62a1435232d4d2a9d3f0396a66b8bf9",
            "5f00b23f50a04612919881b73fe96bf6",
            "4710bf326dfa42dcb3c0420886711b0d",
            "b49c3229cf2b4affbbde0f8f490cd8c7",
            "e9ad683602e5478ca3ad2f4cfe2f2d94",
            "ba2d9323dbae490f90d0a64f3b7cc40c",
            "ad634fa778f041f6848d84ff5abe6fd3",
            "5e5708f243d64a1dbed4e3e8e483b26b",
            "6b2c0466a096480ab3b0161aa74b0422",
            "67b3ebcdaaab4e85917002f71e4a75b8",
            "5f0db5da847f4ad4906b578a735acb26",
            "9f7085ef4b8b4db694d46f4ac79aaf2c",
            "a511d0a2e45047f691fc12e4c0984540",
            "3454957be65b46f1b9cd0eb99858596a",
            "d6d7d85fa6494572b146f1999a4240cf",
            "28a1405b083e459ba4e37f63977781da",
            "26b58ce22cef44c3ac9ee355d4432a1c",
            "501ef17a7fbf47538e53afe7ad766f98",
            "8f3b0d0e702c4f019c1bf23d63cd3ff7",
            "4edc22ee041d4ff19e4f044ba2dae547",
            "54cb59632d6b421ba50216bee10114d5",
            "d43e68fb232b4a90bbb22377d9d46250",
            "a02ee5d24dfa4236ae4296cef3267980",
            "f83a514ec69a41a8996337f519a80b0f",
            "cd392024df014b539641235f6dd27dec",
            "b9118480ee374c489db8206f42648a56",
            "5459045e6ba64ee4a65ca2020f5d91ba",
            "d34c7d7c26904dc68d05aa885b93a645",
            "4aec0aff677d49788b7c7716ca084321",
            "e814e632411a46b58cc341e70cb26cc2",
            "99ec41a0393a45aba99a504c099633c8",
            "64c6361e66884f4ab6ba7cdd2e12d14a",
            "34ec3c7b95b649ee8ffd705c22e12e47",
            "48f915c0dc124e2a8eac319c8035199a",
            "12d363d28a3f458987fc47e06843ce16",
            "3ed805d048bb43d192a4ecbd00972aa5",
            "0f514fed5e3d4d858ebc1f1381484207",
            "5ab4a1411a42485ea8c1bbf763d4099d",
            "baf12c322f2a4800b94408770893d3a8",
            "19e2300cee594bddad8cdad2ea917c0f",
            "45bd09d952bd46e58037842c78a26622",
            "83a3a4d195aa44ddb2b93535d8369ae1",
            "92328a2fcffb45919755bdc51c93c967",
            "ce15eda59d5b4dc4a94912d504a18889",
            "06f0b80182f045a9a1e7f8e1cb5a5588",
            "8b949922a7514ae89050a7cd948912d9",
            "e40d0343536f47f88aae0183caa950a4",
            "6f036002dd6344dabd3eb037279df66a",
            "d8de3539e08441a8a0ad89dbf5f486e1",
            "fb10ad8788c24221ab712f2335f58356",
            "f48e57a83be5412098d3a1e77773297e",
            "99621fc8e95042b5bc12090a3a35f608",
            "1c9df67853b140aea39b3304ae3a92df",
            "ed17358b800a41a98a1d8a46a0c83842",
            "185475c5ffc2428c86b27f0c7c953ce9",
            "1d6cd3af7a8945909f4fe246a5760861",
            "f3d099ae7d77441f8a863d869a729470",
            "9aee726927ef43bba1252fc6128f3fd0",
            "fc004ec59aa444caa6e11ef67085bc03",
            "186a2b0953fd41529958707ea8acf29d",
            "1192d67a3b414b88957aaf92bbdc351b",
            "6b92385e11504215832900ab9a57187c"
          ]
        },
        "id": "uGx48HIjA1F2",
        "outputId": "6408a4df-feac-433b-d1fb-ac2dc31e8038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc960e7f54c345c7a850459302e26255"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e5708f243d64a1dbed4e3e8e483b26b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f3b0d0e702c4f019c1bf23d63cd3ff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e814e632411a46b58cc341e70cb26cc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45bd09d952bd46e58037842c78a26622"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99621fc8e95042b5bc12090a3a35f608"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_reviews(text_list):\n",
        "    return [str(t).strip().replace(\"\\n\", \" \") for t in text_list if isinstance(t, str) and len(t.strip()) > 0]"
      ],
      "metadata": {
        "id": "vjFKJZwFA6O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_reviews(product_name, reviews, max_length=150):\n",
        "    cleaned = clean_reviews(reviews)\n",
        "    joined_text = \" \".join(cleaned)\n",
        "    input_text = f\"summarize: {joined_text}\"\n",
        "\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    summary_ids = model.generate(inputs, max_length=max_length, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return f\"**Product:** {product_name}\\n\\n{summary}\""
      ],
      "metadata": {
        "id": "38eMBj4ZA9ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_from_csv(product_name, file, column_name=\"review_text\"):\n",
        "    df = pd.read_csv(file.name)\n",
        "    if column_name not in df.columns:\n",
        "        return f\"Column '{column_name}' not found in uploaded CSV.\"\n",
        "    reviews = df[column_name].tolist()\n",
        "    return summarize_reviews(product_name, reviews)"
      ],
      "metadata": {
        "id": "RVxgG84tA_5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"##  Review Summarization App\")\n",
        "    gr.Markdown(\"Upload a CSV or paste reviews manually. Include the product name to personalize the summary.\")\n",
        "\n",
        "    with gr.Tab(\"Manual Input\"):\n",
        "        product_name_manual = gr.Textbox(label=\"Product Name\", placeholder=\"e.g., Wireless Headphones\")\n",
        "        manual_input = gr.Textbox(lines=12, placeholder=\"Paste multiple reviews here...\")\n",
        "        manual_button = gr.Button(\"Summarize\")\n",
        "        manual_output = gr.Textbox(label=\"Summary\", lines=12, max_lines=20)\n",
        "\n",
        "    with gr.Tab(\"CSV Upload\"):\n",
        "        product_name_csv = gr.Textbox(label=\"Product Name\", placeholder=\"e.g., Wireless Headphones\")\n",
        "        csv_input = gr.File(label=\"Upload CSV\")\n",
        "        column_name = gr.Textbox(value=\"review_text\", label=\"Column name with reviews\")\n",
        "        csv_button = gr.Button(\"Summarize CSV\")\n",
        "        csv_output = gr.Textbox(label=\"Summary\", lines=12, max_lines=20)\n",
        "\n",
        "    manual_button.click(\n",
        "        lambda name, text: summarize_reviews(name, text.split(\"\\n\")),\n",
        "        inputs=[product_name_manual, manual_input],\n",
        "        outputs=manual_output\n",
        "    )\n",
        "\n",
        "    csv_button.click(\n",
        "        summarize_from_csv,\n",
        "        inputs=[product_name_csv, csv_input, column_name],\n",
        "        outputs=csv_output\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "5BMVMqSKBClr",
        "outputId": "d069150b-a661-4498-9774-18b58b8d5d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e618b8e671f2c5471c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e618b8e671f2c5471c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}